{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309aeee6",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30eed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(31415)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc23f6",
   "metadata": {},
   "source": [
    "# IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e74882",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = pd.read_csv(r'/Users/cadodo/Desktop/main/LIP/CSV/ResmMed4000mX1lb0p2yp0p4.csv')\n",
    "BG = pd.read_csv(r'/Users/cadodo/Desktop/main/LIP/CSV/bkg.csv')\n",
    "\n",
    "BG['LABEL'] = 0\n",
    "signals['LABEL'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abb1bc",
   "metadata": {},
   "source": [
    "# SPLITTING BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc06c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "X_bg = BG.loc[:,['normalisedCombinedWeight','MET_px', 'MET_py','jet_e', 'jet_px', 'jet_py', 'jet_pz',\n",
    "                  'ljet_e', 'ljet_px', 'ljet_py','ljet_pz','HT',\n",
    "                  'gen_split','train_weight','LABEL']]  # REMOVER POR ENQUANTO jet_DL1r_max\n",
    "\n",
    "\n",
    "# WEIGHTS OF bg_test\n",
    "nCW_bg_test = (X_bg.loc[X_bg['gen_split'] == 'test'])['normalisedCombinedWeight']\n",
    "\n",
    "# bg_train TO TRAIN AUTOENCODER\n",
    "bg_train = (X_bg.loc[X_bg['gen_split'] == 'train']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                                  'gen_split','train_weight','LABEL'])\n",
    "\n",
    "# bg_test TO JOIN TO signals_test TO TEST AUTOENCODER\n",
    "bg_test = (X_bg.loc[X_bg['gen_split'] == 'test']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                                'gen_split','train_weight','LABEL'])\n",
    "\n",
    "# bg_val TO JOIN TO signals_val TO VALIDATE AUTOENCODER\n",
    "bg_val = (X_bg.loc[X_bg['gen_split'] == 'val']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                              'gen_split','train_weight','LABEL'])\n",
    "\n",
    "\n",
    "# DEFINE LABELS TO USE FOR THE ROC CURVE\n",
    "y_bg = BG.loc[:,['gen_split','LABEL']]\n",
    "\n",
    "y_bg_train = (y_bg.loc[y_bg['gen_split'] == 'train']).drop(columns=['gen_split'])\n",
    "y_bg_test = (y_bg.loc[y_bg['gen_split'] == 'test']).drop(columns=['gen_split'])\n",
    "y_bg_val = (y_bg.loc[y_bg['gen_split'] == 'val']).drop(columns=['gen_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9055867",
   "metadata": {},
   "source": [
    "# SPLITTING SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09996f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "X_signals = signals.loc[:,['normalisedCombinedWeight','MET_px', 'MET_py','jet_e', 'jet_px', 'jet_py', 'jet_pz',\n",
    "                  'ljet_e', 'ljet_px', 'ljet_py','ljet_pz','HT',\n",
    "                  'gen_split','train_weight','LABEL']]    # REMOVER POR ENQUANTO jet_DL1r_max\n",
    "\n",
    "\n",
    "\n",
    "# WEIGHTS OF signals_test\n",
    "nCW_signals_test = (X_signals.loc[X_signals['gen_split'] == 'test'])['normalisedCombinedWeight']\n",
    "\n",
    "\n",
    "\n",
    "signals_train = (X_signals.loc[X_signals['gen_split'] == 'train']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                              'gen_split','train_weight','LABEL'])\n",
    "\n",
    "# signals_test TO JOIN TO bg_test TO TEST AUTOENCODER\n",
    "signals_test = (X_signals.loc[X_signals['gen_split'] == 'test']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                              'gen_split','train_weight','LABEL'])\n",
    "\n",
    "# signals_val TO JOIN TO bg_val TO VALIDATE AUTOENCODER\n",
    "signals_val = (X_signals.loc[X_signals['gen_split'] == 'val']).drop(columns=['normalisedCombinedWeight',\n",
    "                                                              'gen_split','train_weight','LABEL'])\n",
    "\n",
    "\n",
    "# DEFINE LABELS TO USE FOR THE ROC CURVE\n",
    "y_signals = signals.loc[:,['gen_split','LABEL']]\n",
    "\n",
    "y_signals_train = (y_signals.loc[y_signals['gen_split'] == 'train']).drop(columns=['gen_split'])\n",
    "y_signals_test = (y_signals.loc[y_signals['gen_split'] == 'test']).drop(columns=['gen_split'])\n",
    "y_signals_val = (y_signals.loc[y_signals['gen_split'] == 'val']).drop(columns=['gen_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f95c95",
   "metadata": {},
   "source": [
    "# DEFINE WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3757c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BG WEIGHTS\n",
    "weight_bg_train = (X_bg.loc[X_bg['gen_split'] == 'train'])['train_weight'] \n",
    "weight_bg_test = (X_bg.loc[X_bg['gen_split'] == 'test'])['train_weight']\n",
    "weight_bg_val = (X_bg.loc[X_bg['gen_split'] == 'val'])['train_weight']\n",
    "\n",
    "# SIGNALS WEIGHTS\n",
    "weight_signals_train = (X_signals.loc[X_signals['gen_split'] == 'train'])['train_weight']\n",
    "weight_signals_test = (X_signals.loc[X_signals['gen_split'] == 'test'])['train_weight']\n",
    "weight_signals_val = (X_signals.loc[X_signals['gen_split'] == 'val'])['train_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081277f",
   "metadata": {},
   "source": [
    "# SUM WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2ac8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights_train (BG, signals): (0.9999999999999982, 1.0)\n",
      "class_weights_test (BG, signals): (0.9999999999999997, 1.0)\n",
      "class_weights_val (BG, signals): (1.0000000000000004, 1.0)\n"
     ]
    }
   ],
   "source": [
    "class_weights_train = (weight_bg_train.values.sum(),weight_signals_train.values.sum())\n",
    "class_weights_test = (weight_bg_test.values.sum(),weight_signals_test.values.sum())\n",
    "class_weights_val = (weight_bg_val.values.sum(),weight_signals_val.values.sum())\n",
    "\n",
    "print(\"class_weights_train (BG, signals):\",class_weights_train)\n",
    "print(\"class_weights_test (BG, signals):\",class_weights_test)\n",
    "print(\"class_weights_val (BG, signals):\",class_weights_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92d7b6",
   "metadata": {},
   "source": [
    "# CONCATING DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6416ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN NECESSARY CSVs FOR X\n",
    "X_train = bg_train\n",
    "X_test = pd.concat([signals_test, bg_test], ignore_index=True)\n",
    "X_val = bg_val\n",
    "\n",
    "# JOIN NECESSARY CSVs FOR y\n",
    "y_test = pd.concat([y_signals_test, y_bg_test], ignore_index=True).values\n",
    "y_val = y_bg_val\n",
    "\n",
    "# JOIN NECESSARY CSVs FOR weight\n",
    "weight_train = weight_bg_train.values\n",
    "weight_test = pd.concat([weight_signals_test, weight_bg_test], ignore_index=True).values.reshape(-1,1)\n",
    "weight_val = weight_bg_val\n",
    "nCW_test = pd.concat([nCW_signals_test, nCW_bg_test], ignore_index=True).values\n",
    "nCW_test = nCW_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495b9a4",
   "metadata": {},
   "source": [
    "# STANDARDISATION OF INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b133dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean and variance:\n",
      "MET_px   :  0.8456 +/- 314.9951\n",
      "MET_py   : -3.0400 +/- 315.0266\n",
      "jet_e    : 698.2610 +/- 424.8866\n",
      "jet_px   : -1.0216 +/- 351.9621\n",
      "jet_py   :  3.0931 +/- 353.5471\n",
      "jet_pz   : -5.0986 +/- 645.8425\n",
      "ljet_e   : 726.7014 +/- 394.2431\n",
      "ljet_px  : -1.1067 +/- 365.4329\n",
      "ljet_py  :  2.8156 +/- 366.9482\n",
      "ljet_pz  : -5.3815 +/- 638.0405\n",
      "HT       : 1115.6198 +/- 473.4075\n",
      "\n",
      "Standardised mean and variance:\n",
      "MET_px   : -0.0000 +/-  1.0000\n",
      "MET_py   :  0.0000 +/-  1.0000\n",
      "jet_e    :  0.0000 +/-  1.0000\n",
      "jet_px   :  0.0000 +/-  1.0000\n",
      "jet_py   :  0.0000 +/-  1.0000\n",
      "jet_pz   :  0.0000 +/-  1.0000\n",
      "ljet_e   :  0.0000 +/-  1.0000\n",
      "ljet_px  :  0.0000 +/-  1.0000\n",
      "ljet_py  :  0.0000 +/-  1.0000\n",
      "ljet_pz  : -0.0000 +/-  1.0000\n",
      "HT       : -0.0000 +/-  1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Original mean and variance:\")\n",
    "for feature, mean, std in zip(X_train.columns,X_train.mean(0), X_train.std(0)):\n",
    "      print(\"{:9}: {:7.4f} +/- {:7.4f}\".format(feature,mean,std))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns = X_test.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val),columns = X_val.columns)\n",
    "\n",
    "\n",
    "print(\"\\nStandardised mean and variance:\")\n",
    "for feature, mean, std in zip(X_train.columns,X_train.mean(0), X_train.std(0)):\n",
    "      print(\"{:9}: {:7.4f} +/- {:7.4f}\".format(feature,mean,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "785938dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MET_px     False\n",
       "MET_py     False\n",
       "jet_e      False\n",
       "jet_px     False\n",
       "jet_py     False\n",
       "jet_pz     False\n",
       "ljet_e     False\n",
       "ljet_px    False\n",
       "ljet_py    False\n",
       "ljet_pz    False\n",
       "HT         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9104904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MET_px     False\n",
       "MET_py     False\n",
       "jet_e      False\n",
       "jet_px     False\n",
       "jet_py     False\n",
       "jet_pz     False\n",
       "ljet_e     False\n",
       "ljet_px    False\n",
       "ljet_py    False\n",
       "ljet_pz    False\n",
       "HT         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isinf(X_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12b357d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3438041, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab114e",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab75381",
   "metadata": {},
   "source": [
    "Create a sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1b3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    # Uses (z_mean, z_log_var) to sample z, the vector encoding a digit\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        \n",
    "        batch = tf.shape(z_mean)[0]   # tf.shape returns a 1-D integer tensor representing the shape of input\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))    # Outputs random values from a normal distribution.\n",
    "        \n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4cae8",
   "metadata": {},
   "source": [
    "Build the ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39a8dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 11), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_16/Relu:0', description=\"created by layer 'dense_16'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='dense_17/Relu:0', description=\"created by layer 'dense_17'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='dense_18/Relu:0', description=\"created by layer 'dense_18'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='z_mean/BiasAdd:0', description=\"created by layer 'z_mean'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='z_log_var/BiasAdd:0', description=\"created by layer 'z_log_var'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='sampling_4/add:0', description=\"created by layer 'sampling_4'\") \n",
      "\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 11)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 64)                   768       ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 32)                   2080      ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 16)                   528       ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 2)                    34        ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 2)                    34        ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " sampling_4 (Sampling)       (None, 2)                    0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3444 (13.45 KB)\n",
      "Trainable params: 3444 (13.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "latent_dim = 2\n",
    "shape = X_train.shape[1]   # Number of features\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(shape,))    # A shape tuple (integers), not including the batch size. \n",
    "print(encoder_inputs,'\\n')                      # For instance, shape=(11,) indicates that the expected \n",
    "                                                # input will be batches of 11-dimensional vectors.\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(encoder_inputs)\n",
    "print(x,'\\n')\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "print(x,'\\n')\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "print(x,'\\n')\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "print(z_mean,'\\n')\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "print(z_log_var,'\\n')\n",
    "\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "print(z,'\\n')\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19903ca5",
   "metadata": {},
   "source": [
    "Build the DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0beeecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='dense_27/Relu:0', description=\"created by layer 'dense_27'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='dense_28/Relu:0', description=\"created by layer 'dense_28'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_29/Relu:0', description=\"created by layer 'dense_29'\") \n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 11), dtype=tf.float32, name=None), name='dense_30/BiasAdd:0', description=\"created by layer 'dense_30'\") \n",
      "\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                48        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3419 (13.36 KB)\n",
      "Trainable params: 3419 (13.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))   # (None, 2)\n",
    "print(latent_inputs,'\\n')\n",
    "\n",
    "x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "print(x,'\\n')\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "print(x,'\\n')\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "print(x,'\\n')\n",
    "\n",
    "decoder_outputs = layers.Dense(shape, activation=None)(x)   # Get back the initial number of features (None, 11)\n",
    "print(decoder_outputs,'\\n')\n",
    "\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852019cc",
   "metadata": {},
   "source": [
    "Custom train_step and define VAE as a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4dec07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)     # <- Not encoding properly idk why\n",
    "            reconstruction = self.decoder(z) \n",
    "            \n",
    "            # Mean Squared Error\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            reconstruction_loss = tf.reduce_mean(mse(data, reconstruction))   # tf.reduce_mean >> tf.reduce_sum ??\n",
    "            \n",
    "            # KL Divergence Error\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            \n",
    "            # Total Loss -> MSE + KL\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        #clip_value = 0.5\n",
    "        \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        \n",
    "        #clipped_grads = [tf.clip_by_value(g, -clip_value, clip_value) for g in grads]\n",
    "        #self.optimizer.apply_gradients(zip(clipped_grads, self.trainable_weights))\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507af484",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4d48024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 16:35:51.074366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3220/3358 [===========================>..] - ETA: 1s - loss: nan - reconstruction_loss: nan - kl_loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.0001\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#X = pd.concat([X_train,X_test], ignore_index=True)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(0.0001))\n",
    "\n",
    "#X = pd.concat([X_train,X_test], ignore_index=True)\n",
    "\n",
    "vae.fit(X_train, epochs=30, batch_size=1024)   # loss: nan - reconstruction_loss: nan - kl_loss: nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df9cfd",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa09b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda77c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(2000,11)  # Create random X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ae33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z = mymodel.encoder(x) # encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ebae5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 2), dtype=float32, numpy=\n",
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cb0057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 2), dtype=float32, numpy=\n",
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17df6a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 2), dtype=float32, numpy=\n",
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213385c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
